{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yjbmc6QQ7jpI",
        "outputId": "5d6d78ed-1b51-41b8-a282-22c0a42ba504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets torch accelerate evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTaTAd-N7nHz"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, TrainingArguments, Trainer\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "import evaluate\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20ZYyo3S8Rb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90a78734-f76b-4ce4-f756-3d176c8ec981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"multi_news\")\n",
        "\n",
        "train_ds = dataset[\"train\"].shuffle(seed=42).select(range(int(len(dataset[\"train\"]) * 0.05)))  # 5% of data\n",
        "eval_ds = dataset[\"validation\"].shuffle(seed=42).select(range(int(len(dataset[\"validation\"]) * 0.05)))  # 5% of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipEhK93l8pOU"
      },
      "outputs": [],
      "source": [
        "model_name = \"sshleifer/distilbart-cnn-12-6\"\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgMOVOKm9t1_"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    inputs = tokenizer(\n",
        "        examples[\"document\"],\n",
        "        padding=\"longest\",  # Dynamically pads to longest sequence in batch\n",
        "        max_length=1024,\n",
        "        truncation=True,\n",
        "    )\n",
        "    targets = tokenizer(\n",
        "        examples[\"summary\"],\n",
        "        padding=\"longest\",\n",
        "        max_length=150,\n",
        "        truncation=True,\n",
        "    )\n",
        "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
        "    return inputs\n",
        "\n",
        "# Apply tokenization\n",
        "tokenized_train = train_ds.map(preprocess_function, batched=True)\n",
        "tokenized_eval = eval_ds.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove extra columns that are not inputs for the model\n",
        "tokenized_train = tokenized_train.remove_columns([\"summary\", \"document\"])\n",
        "tokenized_eval = tokenized_eval.remove_columns([\"summary\", \"document\"])"
      ],
      "metadata": {
        "id": "VjEWZhjiLBuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJVu0E2aBArU"
      },
      "outputs": [],
      "source": [
        "# Load BLEU metric\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "\n",
        "def compute_bleu(pred):\n",
        "    predictions, labels = pred\n",
        "\n",
        "    # Convert logits to token IDs using argmax\n",
        "    if isinstance(predictions, tuple):\n",
        "        predictions = predictions[0]  # Extract first element\n",
        "\n",
        "    # Ensure predictions are NumPy arrays\n",
        "    if isinstance(predictions, np.ndarray):\n",
        "        predictions = np.argmax(predictions, axis=-1)  # Convert logits to token IDs\n",
        "        predictions = predictions.tolist()  # Convert to list\n",
        "\n",
        "    # Convert labels to lists\n",
        "    labels = labels.tolist() if isinstance(labels, np.ndarray) else labels\n",
        "\n",
        "    # Decode into text\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    references = [[ref] for ref in tokenizer.batch_decode(labels, skip_special_tokens=True)]\n",
        "\n",
        "    # Compute BLEU score\n",
        "    result = bleu.compute(predictions=decoded_preds, references=references)\n",
        "\n",
        "    return {\"bleu\": result[\"bleu\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQFh1U4kBRcz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ce292fa-0b2a-42f8-e673-b605e15e6a23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"distilbart-finetuned-multinews\",\n",
        "    run_name=\"distilbart-multi-news-run\",\n",
        "    report_to=\"none\",  # Disable wandb\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    push_to_hub=False,\n",
        "    eval_accumulation_steps=4  # Reduce memory usage\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure model is on GPU\n",
        "model.to(\"cuda\")\n",
        "\n",
        "# Check dataset device\n",
        "print(\"Debug: Checking dataset tensors on GPU\")\n",
        "print(\"Sample Tokenized Train Data:\", tokenized_train[0])\n",
        "\n",
        "# Test a forward pass before training\n",
        "inputs = tokenizer(\"This is a test input.\", return_tensors=\"pt\").to(\"cuda\")\n",
        "outputs = model.generate(**inputs)\n",
        "print(\"Debug: Model test passed. Output:\", tokenizer.batch_decode(outputs, skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f3kMuSlICy7",
        "outputId": "5397905d-5e7e-4d2b-91cd-88d54ba0d4c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Debug: Checking dataset tensors on GPU\n",
            "Sample Tokenized Train Data: {'input_ids': [0, 45717, 37053, 34080, 14452, 18, 1354, 34, 555, 10, 299, 6794, 29322, 1741, 18, 665, 3653, 4, 1437, 50118, 1437, 50118, 16083, 1729, 6, 365, 6, 3790, 4248, 975, 226, 3586, 3765, 510, 6433, 18, 5168, 21425, 94, 186, 6, 511, 11, 5, 18424, 9, 27557, 2191, 4444, 6, 6823, 2068, 17251, 6178, 27757, 104, 6, 344, 22722, 7025, 2076, 226, 23075, 1301, 8, 26204, 975, 13548, 725, 28889, 6997, 4581, 4, 1437, 50118, 1437, 50118, 1405, 80, 5396, 6, 4729, 2444, 8041, 29615, 37053, 8, 12413, 10227, 3935, 6, 4005, 19, 49, 809, 26484, 150, 2201, 56, 69, 2549, 15158, 6, 847, 8, 25845, 71, 69, 20941, 58, 10122, 909, 4, 1437, 50118, 1437, 50118, 38659, 1437, 50118, 1437, 50118, 20, 21425, 6, 2034, 15, 4448, 14170, 2666, 6, 34, 10, 7397, 7266, 8, 16, 98, 5451, 24, 630, 75, 240, 10, 1203, 4, 1437, 50118, 1437, 50118, 14474, 6218, 8289, 23, 5, 276, 86, 25, 2201, 1602, 5, 13692, 25, 22, 1694, 8602, 845, 1437, 50118, 1437, 50118, 509, 3653, 26, 35, 22, 1213, 3559, 75, 101, 2340, 408, 23, 70, 142, 51, 2551, 7, 33, 117, 5823, 50, 310, 21843, 59, 106, 4, 1437, 50118, 1437, 50118, 22, 100, 216, 51, 682, 685, 49, 1150, 53, 49, 1498, 1762, 9, 11926, 2425, 24, 21, 101, 2494, 130, 12129, 72, 45056, 49085, 15483, 2250, 9151, 11873, 5, 1053, 1437, 50118, 1437, 50118, 901, 30735, 22664, 248, 3036, 2250, 9151, 4624, 15, 2615, 833, 46654, 1437, 50118, 1437, 50118, 5066, 417, 1527, 1159, 8, 30735, 22664, 1832, 139, 213, 865, 12, 179, 12, 4539, 480, 98, 24, 817, 746, 1472, 14, 18, 1159, 1147, 1871, 10, 2335, 1440, 1620, 52, 174, 47, 94, 353, 6, 2804, 8, 2201, 2250, 794, 30735, 22664, 15, 5, 340, 8, 1276, 7, 244, 66, 4, 2647, 24, 1006, 480, 30735, 22664, 21, 66, 29043, 19, 10, 6777, 9727, 42, 983, 4, 274, 13299, 219, 8801, 2156, 5, 1651, 14, 8262, 30735, 22664, 6, 3026, 201, 24, 40, 185, 59, 112, 12, 176, 688, 13, 123, 7, 120, 341, 7, 5, 512, 480, 8, 37, 581, 28, 878, 198, 11, 117, 86, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [0, 2383, 4557, 11, 233, 7, 988, 2250, 17, 27, 29, 130, 408, 6, 10, 80, 12, 28570, 2335, 300, 10, 278, 9, 10562, 42, 983, 4, 13788, 431, 94, 353, 14, 5, 2722, 29, 1790, 58, 667, 7, 1693, 68, 176, 6, 151, 7, 582, 13, 5, 6777, 9727, 578, 2362, 2136, 15, 141, 203, 51, 3162, 4, 1614, 18911, 6, 4420, 578, 4297, 14, 847, 14186, 189, 45, 4442, 7, 70, 383, 2722, 139, 12, 28371, 35, 83, 1300, 54, 6957, 2201, 2250, 18, 485, 29618, 30, 6794, 15240, 661, 5095, 1063, 14721, 3320, 242, 3026, 5, 2083, 5, 1159, 58, 101, 44, 48, 9983, 12129, 4, 17, 46, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "Debug: Model test passed. Output: [' This is a test input. This is the first time we have used this input . This input has been used in the past for a test run. This input will be used to test a new version of this input. We are happy to present this information to the public.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1SJF4TTBUVP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "c01954f3-2b45-4e84-d81f-b4438139bec8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1686' max='1686' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1686/1686 13:11, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Bleu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.709300</td>\n",
              "      <td>2.522746</td>\n",
              "      <td>0.208086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.324500</td>\n",
              "      <td>2.503051</td>\n",
              "      <td>0.210742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.129100</td>\n",
              "      <td>2.524327</td>\n",
              "      <td>0.212036</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:2758: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1686, training_loss=2.3493362372456073, metrics={'train_runtime': 792.3731, 'train_samples_per_second': 8.511, 'train_steps_per_second': 2.128, 'total_flos': 1.0439119104638976e+16, 'train_loss': 2.3493362372456073, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Initialize trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_eval,\n",
        "    compute_metrics=compute_bleu\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMskas1lBf4y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15546dc5-6055-4267-9e31-00408761ef72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('distilbart-finetuned-multinews/tokenizer_config.json',\n",
              " 'distilbart-finetuned-multinews/special_tokens_map.json',\n",
              " 'distilbart-finetuned-multinews/vocab.json',\n",
              " 'distilbart-finetuned-multinews/merges.txt',\n",
              " 'distilbart-finetuned-multinews/added_tokens.json',\n",
              " 'distilbart-finetuned-multinews/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "trainer.save_model(\"distilbart-finetuned-multinews\")\n",
        "tokenizer.save_pretrained(\"distilbart-finetuned-multinews\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbpX4F-fBo6M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "87b4c2fb-ed43-4641-e2b9-b83d360c5119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: distilbart-finetuned-multinews/ (stored 0%)\n",
            "  adding: distilbart-finetuned-multinews/merges.txt (deflated 53%)\n",
            "  adding: distilbart-finetuned-multinews/generation_config.json (deflated 47%)\n",
            "  adding: distilbart-finetuned-multinews/config.json (deflated 62%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-1686/ (stored 0%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-1686/generation_config.json (deflated 47%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-1686/config.json (deflated 62%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-1686/rng_state.pth (deflated 25%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-1686/scheduler.pt (deflated 56%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-1686/training_args.bin (deflated 52%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-1686/model.safetensors (deflated 7%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-1686/optimizer.pt (deflated 9%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-1686/trainer_state.json (deflated 65%)\n",
            "  adding: distilbart-finetuned-multinews/training_args.bin (deflated 52%)\n",
            "  adding: distilbart-finetuned-multinews/vocab.json (deflated 59%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-562/ (stored 0%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-562/generation_config.json (deflated 47%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-562/config.json (deflated 62%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-562/rng_state.pth (deflated 25%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-562/scheduler.pt (deflated 56%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-562/training_args.bin (deflated 52%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-562/model.safetensors (deflated 7%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-562/optimizer.pt (deflated 9%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-562/trainer_state.json (deflated 56%)\n",
            "  adding: distilbart-finetuned-multinews/model.safetensors (deflated 7%)\n",
            "  adding: distilbart-finetuned-multinews/tokenizer_config.json (deflated 76%)\n",
            "  adding: distilbart-finetuned-multinews/special_tokens_map.json (deflated 85%)\n",
            "  adding: distilbart-finetuned-multinews/tokenizer.json (deflated 82%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-1124/ (stored 0%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-1124/generation_config.json (deflated 47%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-1124/config.json (deflated 62%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-1124/rng_state.pth (deflated 25%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-1124/scheduler.pt (deflated 55%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-1124/training_args.bin (deflated 52%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-1124/model.safetensors (deflated 7%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-1124/optimizer.pt (deflated 9%)\n",
            "  adding: distilbart-finetuned-multinews/checkpoint-1124/trainer_state.json (deflated 61%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3cfdbf10-7dbe-4c19-b4a3-00c33f8eb80c\", \"distilbart-finetuned-multinews.zip\", 11236822820)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "!zip -r distilbart-finetuned-multinews.zip distilbart-finetuned-multinews\n",
        "files.download(\"distilbart-finetuned-multinews.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh distilbart-finetuned-multinews.zip"
      ],
      "metadata": {
        "id": "gQr64I_wVv-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69481146-c209-4b56-ef3d-9af3809b62f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 11G Mar 14 07:33 distilbart-finetuned-multinews.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aStlI-hmVzsI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b44e4ade-88ed-4672-83e5-a7fa07f4bff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zdIz-8fUL-f-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yUi0Opq5JFrq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}